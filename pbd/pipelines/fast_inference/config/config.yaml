pipeline:
  name: ocr_pipeline
  enable_cache: false
  settings:
    docker:
      parent_image: "ghcr.io/atharva-phatak/pbd-fast_inference:latest"
      skip_build: true
    kubernetes_orchestrator:
      pod_settings:
        resources:
          requests:
            cpu: "4"
            memory: "3Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "6"
            memory: "4Gi"
            nvidia.com/gpu: "1"
        env_from:
          - secretRef:
              name: "aws-credentials"
        labels:
          app: "ocr-pipeline"
          component: "step"
      orchestrator_pod_settings:
        resources:
          requests:
            cpu: "2"
            memory: "70Mi"
          limits:
            cpu: "4"
            memory: "256Mi"
        env_from:
          - secretRef:
              name: "aws-credentials"
        labels:
          app: "zenml-orchestrator"
          component: "orchestrator"

  steps:
    download_from_minio:
      parameters:
        endpoint: "minio-service:9000"
        bucket: "images-bucket"
        object_key: "ocr/test.zip"
        local_path: "/tmp/images.zip"

    extract_zip:
      parameters:
        extract_to: "/tmp/images"

    ocr_images:
      parameters:
        model_config:
          tok_model_id="HuggingFaceTB/SmolVLM2-256M-Video-Instruct",
          quantized_model_id="ggml-org/SmolVLM2-256M-Video-Instruct-GGUF",
          quantized_filename="SmolVLM2-256M-Video-Instruct-Q8_0.gguf",
        generation_config:
          temperature: 0.7
          top_p: 0.1
          max_tokens: 512
        prompt: "Describe this image in detail."
